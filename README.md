# HI2-ADAM: Historical Intra-personal Inter-personal ADAptive Multimodal Model for Adapted Behavior Synthesis

## Authors: Jieyeon Woo, Mireille Fares, Catherine Pelachaud, Catherine Achard

**Abstract**: Socially Interactive Agents (SIAs), embodied agents or humanoid robots, display similar behavior as humans. We propose HI2-ADAM, a novel approach synthesizing adaptive facial gestures for SIAs while interacting with Users and acting interchangeably as a speaker or as a listener. Our model is characterized by modality memory encoding schema (modality corresponding to either speech or facial gestures) and makes use of attention mechanisms to capture the intra-personal and inter-personal relationships while assuring motion continuity. We validate our approach by conducting objective and subjective evaluations and comparing it with the state-of-the-art approaches.

Demo video of synthesized SIA behavior via HI2-ADAM:\
The following video shows our HI2-ADAM model's generated adaptive SIA behavior visualized on the GRETA platform. Please click on the image below to watch the video.

[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/8b1LgkOZPU0/0.jpg)](https://www.youtube.com/watch?v=8b1LgkOZPU0)

The code will be published soon.
